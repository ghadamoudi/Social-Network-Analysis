{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was obtained from Heedzy at: https://heedzy.com/. It includes 100 reviews of Hungerstation App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data file\n",
    "\n",
    "df = pd.read_csv(\"hungerstation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "hm6pa5Af4qbE",
    "outputId": "7bf41859-f291-44ae-a785-12cd486a53a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>اتمنى الانتباه</td>\n",
       "      <td>تغليف المشروبات باحكام (الحار والبارد) للتاكد ...</td>\n",
       "      <td>'أميرة'</td>\n",
       "      <td>2</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>اعلاناتهم أكبر من واقعهم</td>\n",
       "      <td>جاهز وبس</td>\n",
       "      <td>دح 911</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>سيء جدا</td>\n",
       "      <td>لا يوجد اي التزام بمواعيد التوصيل ، الطلب يجلس...</td>\n",
       "      <td>y_awdah</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>فاشل</td>\n",
       "      <td>اقل من نجمه ونصابين ويزيدون فلوس فجاه بدون سبب...</td>\n",
       "      <td>ii.jem2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>horrible</td>\n",
       "      <td>canceled my order on me did not provide any in...</td>\n",
       "      <td>Dead Rat2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source        Date                     Title  \\\n",
       "0  HungerStation  2021-11-02            اتمنى الانتباه   \n",
       "1  HungerStation  2021-11-02  اعلاناتهم أكبر من واقعهم   \n",
       "2  HungerStation  2021-11-02                   سيء جدا   \n",
       "3  HungerStation  2021-11-02                      فاشل   \n",
       "4  HungerStation  2021-11-02                  horrible   \n",
       "\n",
       "                                             Content       Name  Rating  \\\n",
       "0  تغليف المشروبات باحكام (الحار والبارد) للتاكد ...    'أميرة'       2   \n",
       "1                                           جاهز وبس     دح 911       1   \n",
       "2  لا يوجد اي التزام بمواعيد التوصيل ، الطلب يجلس...    y_awdah       1   \n",
       "3  اقل من نجمه ونصابين ويزيدون فلوس فجاه بدون سبب...    ii.jem2       1   \n",
       "4  canceled my order on me did not provide any in...  Dead Rat2       1   \n",
       "\n",
       "  Version  \n",
       "0  5.13.2  \n",
       "1  5.13.2  \n",
       "2  5.13.2  \n",
       "3  5.13.2  \n",
       "4  5.13.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'تغليف المشروبات باحكام (الحار والبارد) للتاكد من ان المندوب لم لم يستخدم المشروب'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There’s is ZERO customer service. I never received an order, was charged for it and then was never refunded. To add insult to injury they marked my issue as resolved. I cannot get through to them anymore. Absolutely disgraceful and dishonest. Avoid this crooked company like the plague. If I could give -10 stars I would. Utterly horrid!\n"
     ]
    }
   ],
   "source": [
    "print (df['Content'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "افضل من مرسول 🤍🤍\n"
     ]
    }
   ],
   "source": [
    "print (df['Content'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it first time only, to install the library.\n",
    "#!pip install camel-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic Preprocessing Pipeline\n",
    "There are many tools for processing Arabic text: NLTK, Gensim, Farasa, MADAMIRA and Stanford CoreNLP, CAMeL. We will use CAMeL, NLTK, and Gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Dediacritization (إزالة التشكيل)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  إِنَّ اللَّهَ وَمَلَائِكَتَهُ يُصَلُّونَ عَلَى النَّبِيِّ ۚ يَا أَيُّهَا الَّذِينَ آمَنُوا صَلُّوا عَلَيْهِ وَسَلِّمُوا تَسْلِيمًا \n",
      "after :  إن الله وملائكته يصلون على النبي ۚ يا أيها الذين آمنوا صلوا عليه وسلموا تسليما \n"
     ]
    }
   ],
   "source": [
    "# import the dediacritization tool\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "\n",
    "text  = \"إِنَّ اللَّهَ وَمَلَائِكَتَهُ يُصَلُّونَ عَلَى النَّبِيِّ ۚ يَا أَيُّهَا الَّذِينَ آمَنُوا صَلُّوا عَلَيْهِ وَسَلِّمُوا تَسْلِيمًا \"\n",
    "text2 = dediac_ar(text)\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", text2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Normalizing Alif and Tah Marbotah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "\n",
    "def ortho_normalize(text):\n",
    "    text = normalize_alef_maksura_ar(text)\n",
    "    text = normalize_alef_ar(text)\n",
    "    text = normalize_teh_marbuta_ar(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  الأم الآلام الإمرأة\n",
      "after :  الام الالام الامراه\n"
     ]
    }
   ],
   "source": [
    "text  = \"الأم الآلام الإمرأة\"\n",
    "text2 = ortho_normalize(text)\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", text2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Remove English Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english(text):\n",
    "    text = re.sub(r'\\s*[A-Za-z]+\\b', '' , text)\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  There’s is ZERO customer service. I never received an order, was charged for it and then was never refunded. To add insult to injury they marked my issue as resolved. I cannot get through to them anymore. Absolutely disgraceful and dishonest. Avoid this crooked company like the plague. If I could give -10 stars I would. Utterly horrid!\n",
      "after :  ’.,..... -10.!\n"
     ]
    }
   ],
   "source": [
    "text = df['Content'][9]\n",
    "text2 = remove_english(text)\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    # define a list of arabic and english punctiations that we want to get rid of in our text\n",
    "    punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    text = text.translate(translator)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- maketrans( ) method creates a one to one mapping of a character to its translation/replacement.\n",
    "- translate( ) method makes a copy of a string with a specific set of values substituted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  لا يوجد اي التزام بمواعيد التوصيل ، الطلب يجلس ساعتين لين يجيك ! ويجي بارد والمندوب يالله يرد ما تطور ولا شي بهنقرستيشن من يوم طلع للحين ليتهم يتعلمون من جاهز بس\n",
      "after :  لا يوجد اي التزام بمواعيد التوصيل  الطلب يجلس ساعتين لين يجيك  ويجي بارد والمندوب يالله يرد ما تطور ولا شي بهنقرستيشن من يوم طلع للحين ليتهم يتعلمون من جاهز بس\n"
     ]
    }
   ],
   "source": [
    "text = df['Content'][2]\n",
    "text2 = remove_punc(text)\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  افضل من مرسول 🤍🤍\n",
      "after :  افضل من مرسول \n"
     ]
    }
   ],
   "source": [
    "# you have to install this first by: !pip install demoji\n",
    "\n",
    "import demoji\n",
    "text = df['Content'][13]\n",
    "text2 = demoji.replace(text, '')\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  إِنَّ اللَّهَ وَمَلَائِكَتَهُ يُصَلُّونَ عَلَى النَّبِيِّ ۚ يَا أَيُّهَا الَّذِينَ آمَنُوا صَلُّوا عَلَيْهِ وَسَلِّمُوا تَسْلِيمًا \n",
      "after :  ['ان', 'الله', 'وملائكته', 'يصلون', 'علي', 'النبي', 'ۚ', 'يا', 'ايها', 'الذين', 'امنوا', 'صلوا', 'عليه', 'وسلموا', 'تسليما']\n"
     ]
    }
   ],
   "source": [
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "text  = \"إِنَّ اللَّهَ وَمَلَائِكَتَهُ يُصَلُّونَ عَلَى النَّبِيِّ ۚ يَا أَيُّهَا الَّذِينَ آمَنُوا صَلُّوا عَلَيْهِ وَسَلِّمُوا تَسْلِيمًا \"\n",
    "text2 = dediac_ar(text)\n",
    "text2 = ortho_normalize(text2)\n",
    "tokenized = simple_word_tokenize(text2)\n",
    "print (\"before: \", text)\n",
    "print (\"after : \", tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Stop-words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words(\"arabic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ان',\n",
       " 'الله',\n",
       " 'وملائكته',\n",
       " 'يصلون',\n",
       " 'علي',\n",
       " 'النبي',\n",
       " 'ۚ',\n",
       " 'ايها',\n",
       " 'امنوا',\n",
       " 'صلوا',\n",
       " 'وسلموا',\n",
       " 'تسليما']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = [word for word in tokenized if word not in stop_words]\n",
    "clean_text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Stemming or Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حرك\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "st = ISRIStemmer()\n",
    "w = 'حركات'\n",
    "print(st.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other preprocessing include stemming, removing numbers, removing URLs etc, it all depends on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put them all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \n",
    "    # if you need to use this function in other code or notebook \n",
    "    # make sure you import the needed libraries.\n",
    "    \n",
    "    cleaned = dediac_ar(text)\n",
    "    cleaned = ortho_normalize(cleaned)\n",
    "    cleaned = remove_english(cleaned)\n",
    "    cleaned = remove_punc(cleaned)\n",
    "    cleaned = demoji.replace(cleaned, '')\n",
    "    cleaned = tokenized = simple_word_tokenize(cleaned)\n",
    "    cleaned = [word for word in tokenized if word not in stop_words]\n",
    "    cleaned = [st.stem(word) for word in cleaned]\n",
    "    return \" \".join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'طلب جلس ساع لين يجك فضل رسل اشي'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" الطلب يجلس ساعتين لين يجيك !لكن افضل من مرسول 👍🏼👍🏼 مَاشِي \"\n",
    "text2 = clean(text)\n",
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it to all the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>اتمنى الانتباه</td>\n",
       "      <td>غلف شرب حكم حار برد تكد ان ندب خدم شرب</td>\n",
       "      <td>'أميرة'</td>\n",
       "      <td>2</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>اعلاناتهم أكبر من واقعهم</td>\n",
       "      <td>جهز وبس</td>\n",
       "      <td>دح 911</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>سيء جدا</td>\n",
       "      <td>وجد اي تزم مواعيد وصل طلب جلس ساع لين يجك ويج ...</td>\n",
       "      <td>y_awdah</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>فاشل</td>\n",
       "      <td>اقل نجم نصب يزد فلس فجه بدن سبب قئم سعر و سله ...</td>\n",
       "      <td>ii.jem2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HungerStation</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>horrible</td>\n",
       "      <td></td>\n",
       "      <td>Dead Rat2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source        Date                     Title  \\\n",
       "0  HungerStation  2021-11-02            اتمنى الانتباه   \n",
       "1  HungerStation  2021-11-02  اعلاناتهم أكبر من واقعهم   \n",
       "2  HungerStation  2021-11-02                   سيء جدا   \n",
       "3  HungerStation  2021-11-02                      فاشل   \n",
       "4  HungerStation  2021-11-02                  horrible   \n",
       "\n",
       "                                             Content       Name  Rating  \\\n",
       "0             غلف شرب حكم حار برد تكد ان ندب خدم شرب    'أميرة'       2   \n",
       "1                                            جهز وبس     دح 911       1   \n",
       "2  وجد اي تزم مواعيد وصل طلب جلس ساع لين يجك ويج ...    y_awdah       1   \n",
       "3  اقل نجم نصب يزد فلس فجه بدن سبب قئم سعر و سله ...    ii.jem2       1   \n",
       "4                                                     Dead Rat2       1   \n",
       "\n",
       "  Version  \n",
       "0  5.13.2  \n",
       "1  5.13.2  \n",
       "2  5.13.2  \n",
       "3  5.13.2  \n",
       "4  5.13.2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df\n",
    "new_df['Content'] = df['Content'].apply(clean)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These preprocessing step are needed for machine learning algoriyhms. Now you can apply sentiment analysis as we did in English NLP, but you need a labelled dataset. This one is not labelled. You can label it, but it is too small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for text summarization we would not need all the preprocessing steps above. We will see an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an algorithm called TextRank, which depends on PageRank algorithm. \n",
    "- TextRank implementation is available at Gensim library. \n",
    "- PageRank algorithm first developed by Google co-founder Larry Page. \n",
    "- The algorithm rank pages by importance, the most important page is the page that receives the largest number of links from “also” important pages.\n",
    "- It depends on graph theory as it considers a web page as a node and the edges are links (hyperlinks) between pages.\n",
    "- In TextRank, node represent sentences and edges represents similarities between sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The higher the PageRank of a link, the more authoritative it is. \n",
    "We can simplify the PageRank algorithm to describe it as a way for the importance of a webpage to be measured by analyzing the quantity and quality of the links that point to it.\" [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"TextRank – is a graph-based ranking model for text processing which can be used in order to find the most relevant sentences in text and also to find keywords. The algorithm is explained in detail in the paper at https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf\" [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim python library include an implmentation of TextRank. Let's try it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will combine all the sentences together as one long sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hungerstation.csv\")\n",
    "sentences = ''\n",
    "for s in df['Content']:\n",
    "    sentences = sentences + s + '. '\n",
    "\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will import the library that will do all the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextRank\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لا يوجد اي التزام بمواعيد التوصيل ، الطلب يجلس ساعتين لين يجيك !\n",
      "my money is lost and every time i try to contact customer service it gives me a “something went wrong” message \n",
      "They always demand that we come down to take the order even though the delivery charge is very high already.\n",
      "It is only normal that the order is delivered to the doorstep; that is what we pay for after all with the delivery charge.\n",
      "في الطايف المحلات والمطاعم مشغولة او مغلقة ادخل مرسول كله مفتوحة ايش المشكلة كل مره زي كذا ي مغلق او مشغول كرهت البرنامج من زمان على الوضع ذا ولا تغير.\n",
      "It’s worse it application delivery food  I have tried in Saudi Arabia.\n",
      "سحبو الفلوس و تم إلغاء الطلب ولا يوجد طريقة تواصل ولم يتم إسترجاع المبلغ.\n",
      "يعني ياخذ طلبك ويروح مطعم ثاني، ينتظر الطلب بعدين يجيك الاكل بارد.\n",
      "المندوب يقبل الطلب وهو مامعه فلوس.\n",
      "اسوء تطبيق توصيل ممكن تشوفه الاكل يوصل بارد و نص الاكل ماكول الله لا يسامحهم و توصيلهم اغلى من الطلب نفسه.\n",
      "Best app as well as the service they provide incredible..\n",
      "كل وجبة يزيد سعرها في هنقرستيشن بما لا يقل عن ٣ ريال وتوصل الى ٨ ريال… وفوق كذا يتأخر المندوب ويوصلك الاكل بارد.\n",
      "Once the order delivered, this app will be deleted for good..\n",
      "السلام عليكم اولاً المعروف فيني هادئ وما ادقق باشيئ كثير بس للامانة رفع ضغطي سيئ جداً تأخير غير طبيعي يمديك تروح مشي وترجع وهو ماخلص تعليق بالبرنامج والمندوب اتوقع واحد بس يلف الطائف كلها وبعدين يجيك اتمنى يلقو نظرة على برنامج\n",
      "الطلب اخذ ساعتين هذا غير معقول والموظف لايتجاوب ويقول انا لا ادري طلبك عند مـن ؟؟؟؟؟\n",
      "طلبت اكثر من مره من التطبيق والمشكله الطلب ياصل متأخر وبارد وقليلين فهمم \n",
      "ليش جاني خصم 66 ريال قيمة الطلب والتوصيل\n",
      "تطبيق من سيء الى اسواء … السعر اغلى … دايم يتاخر ودايم الاكل يجي بارد.\n",
      "اسعار التوصيل عندكم اغلى من الاكل نفسه وغير هذا مناديبكم يتاخرون دايم ياليت تراجعون اسعار التوصيل !.\n",
      "It’s a really good app but it does lag from time to time and also the delivery fees are kinda expensive 15 SAR so my order can be delivered if the delivery can be a little cheaper then I would 5 stars but for now I will give it a 4.\n",
      "ماتقدر تتواصل مع خدمة العملاء ولايفيدونك بشي والطلب يجيك بعد مايروح المندوب لاكثر من زبون ويجيك بارد.\n",
      "اغلب التعليقات تسب التطبيق بلعكس كل شوي اطلب منه مو اول مره ،مره طلبت حلا ودونات ومن عصائر ومن ماك ويوصل بسرعة مشاء الله بس بعض الاحيان يكون ضغط عندهم.\n",
      "سلامات ماقدر الغي الطلب فرضا طلبت بالغلط وحبيت الغي بنفس الوقت صراحة تطبيق سيء !!!!.\n",
      "المندوب قال اني وصلت الطلب ولم يتم توصيله \n",
      "اخر الليل نصيحه لا تطلب عندكم جاهز وعندكم اكثر من تطبيق.\n",
      "مافي اي مصداقيه بالاكواد ، كود جيران للطلب الاول حطيته و طلع لي المبلغ ووقت الدفع ما انخصم شي ، كلمت خدمة العملاء يقول لازم مايكون التطبيق تحمل قبل كذا بالجوال🙂 \n",
      "After waiting for 45 min the order was cancelled by the app.\n",
      "حقيقا التطبيق جدا سيئ وياخذ مبالغ طائلة للتوصيل وغير دقيق في المواعيد ابدا ، ويوجد تطبيقات افضل منه مثل جاهز وهذا اخر طلبة اطلبه من عندهم بعدها بحذفه.\n",
      "). التطبيق اسعار الوجبات عنده اغلى من المطعم نفسه يعني ياخذون عليك مبلغ التوصيل وزيادة عليه رافعين سعر الوجبة عن سعرها الرسمي في اي مطعم موجود في التطبيق نصيحة تطبيقات التوصيل كثيره فيه افضل منه ب ١٠٠ مره.\n",
      "Worst customer service ever.\n",
      "Delivering a quality service is all we need and you have it HungerStation just please consider all regular customers to have special offers..\n"
     ]
    }
   ],
   "source": [
    "short_summary = summarize(sentences)\n",
    "print(short_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لا يوجد اي التزام بمواعيد التوصيل ، الطلب يجلس ساعتين لين يجيك !\n",
      "my money is lost and every time i try to contact customer service it gives me a “something went wrong” message \n",
      "It is only normal that the order is delivered to the doorstep; that is what we pay for after all with the delivery charge.\n",
      "في الطايف المحلات والمطاعم مشغولة او مغلقة ادخل مرسول كله مفتوحة ايش المشكلة كل مره زي كذا ي مغلق او مشغول كرهت البرنامج من زمان على الوضع ذا ولا تغير.\n",
      "سحبو الفلوس و تم إلغاء الطلب ولا يوجد طريقة تواصل ولم يتم إسترجاع المبلغ.\n",
      "يعني ياخذ طلبك ويروح مطعم ثاني، ينتظر الطلب بعدين يجيك الاكل بارد.\n",
      "اسوء تطبيق توصيل ممكن تشوفه الاكل يوصل بارد و نص الاكل ماكول الله لا يسامحهم و توصيلهم اغلى من الطلب نفسه.\n",
      "Once the order delivered, this app will be deleted for good..\n",
      "طلبت اكثر من مره من التطبيق والمشكله الطلب ياصل متأخر وبارد وقليلين فهمم \n",
      "تطبيق من سيء الى اسواء … السعر اغلى … دايم يتاخر ودايم الاكل يجي بارد.\n",
      "It’s a really good app but it does lag from time to time and also the delivery fees are kinda expensive 15 SAR so my order can be delivered if the delivery can be a little cheaper then I would 5 stars but for now I will give it a 4.\n",
      "المندوب قال اني وصلت الطلب ولم يتم توصيله \n",
      "After waiting for 45 min the order was cancelled by the app.\n",
      "حقيقا التطبيق جدا سيئ وياخذ مبالغ طائلة للتوصيل وغير دقيق في المواعيد ابدا ، ويوجد تطبيقات افضل منه مثل جاهز وهذا اخر طلبة اطلبه من عندهم بعدها بحذفه.\n",
      "). التطبيق اسعار الوجبات عنده اغلى من المطعم نفسه يعني ياخذون عليك مبلغ التوصيل وزيادة عليه رافعين سعر الوجبة عن سعرها الرسمي في اي مطعم موجود في التطبيق نصيحة تطبيقات التوصيل كثيره فيه افضل منه ب ١٠٠ مره.\n"
     ]
    }
   ],
   "source": [
    "# Summarization by ratio\n",
    "\n",
    "summary_by_ratio=summarize(sentences,ratio=0.1)\n",
    "print(summary_by_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اسوء تطبيق توصيل ممكن تشوفه الاكل يوصل بارد و نص الاكل ماكول الله لا يسامحهم و توصيلهم اغلى من الطلب نفسه.\n",
      "تطبيق من سيء الى اسواء … السعر اغلى … دايم يتاخر ودايم الاكل يجي بارد.\n"
     ]
    }
   ],
   "source": [
    "# Summarization by word count\n",
    "\n",
    "summary_by_word_count=summarize(sentences,word_count=30)\n",
    "print(summary_by_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اسوء تطبيق توصيل ممكن تشوفه الاكل يوصل بارد و نص الاكل ماكول الله لا يسامحهم و توصيلهم اغلى من الطلب نفسه.\n",
      "تطبيق من سيء الى اسواء … السعر اغلى … دايم يتاخر ودايم الاكل يجي بارد.\n"
     ]
    }
   ],
   "source": [
    "# Summarization when both ratio & word count is given\n",
    "\n",
    "summary=summarize(sentences, ratio=0.1, word_count=30)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References <br>\n",
    "[1] https://towardsdatascience.com/arabic-nlp-unique-challenges-and-their-solutions-d99e8a87893d    \n",
    "[2] https://www.semrush.com/blog/pagerank/?kw=&cmp=WW_SRCH_DSA_Blog_Core_BU_EN&label=dsa_pagefeed&Network=g&Device=c&utm_content=515715493860&kwid=dsa-1057183199035&cmpid=11776868584&agpid=117384911274&BU=Core&extid=203745206953&adpos=&gclid=CjwKCAiAs92MBhAXEiwAXTi25zTaakLMojcAl13lNgOQLpRPWsdksUPyunVtrDGoS29OWVrW0eHq1hoCEIUQAvD_BwE#header2\n",
    "[3] https://cran.r-project.org/web/packages/textrank/vignettes/textrank.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "TestRank_Text_Summarization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
